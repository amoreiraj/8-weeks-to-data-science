
# 8-Weeks-to-Data-Science  
### A focused 8-week plan to become job-ready in Data Science & Data Engineering. Applying the Pareto Principle to become job-ready in 2 months (Python + SQL + projects).

![Status](https://img.shields.io/badge/status-in_progress-yellow)  
![Python](https://img.shields.io/badge/python-3.13+-blue?logo=python)  
![SQL](https://img.shields.io/badge/sql-practice-green?logo=postgresql)  

# 8-Weeks-to-Data-Science

A focused 8-week plan to become job-ready for entry-level Data Science or Data Engineering roles, emphasising Python, SQL, and portfolio projects. This project leverages the **Pareto Principle (80/20 Rule)** to prioritise the 20% of skills that deliver 80% of the results, ensuring efficient learning for beginners or intermediate learners.

## Project Overview

This repository provides a structured 8-week learning plan to master essential Data Science and Data Engineering skills, including Python (pandas, NumPy, visualisation), SQL (queries, joins, aggregations), and practical projects. It also includes job preparation tips to build a strong resume and portfolio.

## The Pareto Principle in This Project

The **Pareto Principle** (80/20 Rule) states that 80% of outcomes come from 20% of efforts. Applied to this 8-week plan, it means focusing on high-impact skills and tasks to become job-ready quickly:
- **Python**: Master pandas (data manipulation), NumPy (numerical operations), and basic visualisation (matplotlib/seaborn) to cover ~80% of entry-level tasks.
- **SQL**: Learn SELECT, JOINs, GROUP BY, ORDER BY, and basic subqueries, which are used in most data retrieval tasks.
- **Projects**: Build 2–3 portfolio projects (e.g., data analysis dashboard, ETL pipeline) to demonstrate ~80% of what employers seek in entry-level candidates.
- **Job Prep**: Focus on a clean resume, GitHub portfolio, and practising 5–10 common interview questions (e.g., “Explain how you’d clean a dataset” or “Write a SQL query to find top customers”).

## 8-Week Timeline

| Week | Focus | Activities |
|------|-------|------------|
| **1–2** | Python Basics | Learn Python syntax, loops, functions, and pandas (DataFrames, filtering). Practice on LeetCode using deliberate practice. Use spaced repetition for retention. |
| **3–4** | SQL Fundamentals | Master SQL SELECT, JOINs, aggregations on Mode Analytics. Start a simple project (e.g., clean a Kaggle dataset). Use active recall for query practice. |
| **5–6** | Advanced Skills & Projects | Deepen Python (NumPy, visualisation) and SQL (subqueries, window functions). Build a second project (e.g., ETL pipeline with SQLite). Use the Feynman Technique to explain concepts. |
| **7–8** | Job Prep & Polish | Finalise projects, create a GitHub portfolio, and practice interview questions. Apply the Pareto Principle to focus on high-impact job application tasks. |

## Projects

1. **Data Cleaning & Analysis**  
   - **Description**: Clean and analyse a Kaggle dataset (e.g., Titanic or sales data) using pandas and visualise insights with matplotlib/seaborn.  
   - **Tools**: Python, pandas, matplotlib, Kaggle.  
2. **ETL Pipeline**  
   - **Description**: Build a simple ETL pipeline to extract data from a CSV, transform it with Python, and load it into a SQLite database.  
   - **Tools**: Python, pandas, SQLite, SQL.  
3. **Data Dashboard**  
   - **Description**: Create a basic interactive dashboard to visualise dataset insights (e.g., sales trends) using Python and seaborn.  
   - **Tools**: Python, pandas, seaborn, Jupyter Notebook.

## Resources

- **Python**: [FreeCodeCamp’s Python for Data Science](https://www.freecodecamp.org/learn/data-analysis-with-python/) (free), [DataCamp’s Python Fundamentals](https://www.datacamp.com/) (affordable).  
- **SQL**: [Mode Analytics’ SQL Tutorial](https://mode.com/sql-tutorial/) (free), [LeetCode Database Problems](https://leetcode.com/problemset/database/) (free tier).  
- **Projects**: [Kaggle Datasets](https://www.kaggle.com/datasets) for analysis, SQLite for ETL practice.  
- **Job Prep**: [Overleaf Resume Templates](https://www.overleaf.com/gallery/tagged/cv), [StrataScratch](https://www.stratascratch.com/) for interview questions.

## Getting Started

1. Clone this repository: `git clone https://github.com/amoreiraj/8-weeks-to-data-science.git`
2. Follow the weekly plan in the table above.
3. Complete the suggested projects and upload them to your GitHub.
4. Use the resources to practice and refine your skills.
5. Prepare your resume and portfolio for job applications.

## Contributing

Contributions are welcome! Feel free to submit pull requests with additional resources, project ideas, or improvements to the plan.

